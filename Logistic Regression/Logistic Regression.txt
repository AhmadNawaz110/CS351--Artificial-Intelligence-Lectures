<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Logistic Regression in Machine Learning</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --text-color: #333;
            --light-bg: #f9f9f9;
            --border-color: #ddd;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Roboto', sans-serif;
            color: var(--text-color);
            background-color: #f5f5f5;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .slide {
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            padding: 40px;
            margin-bottom: 30px;
            display: none;
            animation: fadeIn 0.5s ease-in-out;
        }
        
        .slide.active {
            display: block;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        h1 {
            color: var(--primary-color);
            font-size: 2.5rem;
            margin-bottom: 20px;
            text-align: center;
        }
        
        h2 {
            color: var(--primary-color);
            font-size: 2rem;
            margin-bottom: 20px;
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 10px;
        }
        
        h3 {
            color: var(--secondary-color);
            font-size: 1.5rem;
            margin: 20px 0 10px;
        }
        
        p {
            margin-bottom: 15px;
            font-size: 1.1rem;
        }
        
        ul, ol {
            margin-left: 25px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 8px;
            font-size: 1.1rem;
        }
        
        .formula {
            background-color: var(--light-bg);
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            text-align: center;
            font-size: 1.2rem;
            font-family: 'Courier New', monospace;
        }
        
        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
        }
        
        button {
            background-color: var(--secondary-color);
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s;
        }
        
        button:hover {
            background-color: #2980b9;
        }
        
        button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }
        
        .slide-indicator {
            text-align: center;
            margin-top: 20px;
            font-size: 1rem;
            color: #7f8c8d;
        }
        
        .code-block {
            background-color: #f8f9fa;
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        
        .example-box {
            background-color: var(--light-bg);
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .example-title {
            font-weight: 500;
            color: var(--secondary-color);
            margin-bottom: 10px;
        }
        
        .svg-container {
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }
        
        .highlight {
            background-color: #fff9c4;
            padding: 2px 4px;
            border-radius: 3px;
        }
        
        .grid-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        @media (max-width: 768px) {
            .grid-container {
                grid-template-columns: 1fr;
            }
        }
        
        .toc {
            background-color: var(--light-bg);
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 30px;
        }
        
        .toc h3 {
            margin-top: 0;
        }
        
        .toc ul {
            list-style-type: none;
            margin-left: 0;
        }
        
        .toc li {
            margin-bottom: 8px;
            padding-left: 15px;
            position: relative;
        }
        
        .toc li:before {
            content: "▶";
            position: absolute;
            left: 0;
            color: var(--secondary-color);
        }
        
        .tab-container {
            margin: 20px 0;
        }
        
        .tabs {
            display: flex;
            border-bottom: 1px solid var(--border-color);
        }
        
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            background-color: var(--light-bg);
            border: 1px solid var(--border-color);
            border-bottom: none;
            margin-right: 5px;
            border-radius: 5px 5px 0 0;
        }
        
        .tab.active {
            background-color: white;
            border-bottom: 1px solid white;
            margin-bottom: -1px;
        }
        
        .tab-content {
            display: none;
            padding: 20px;
            border: 1px solid var(--border-color);
            border-top: none;
        }
        
        .tab-content.active {
            display: block;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="toc">
            <h3>Table of Contents</h3>
            <ul>
                <li onclick="showSlide(0)">Introduction to Logistic Regression</li>
                <li onclick="showSlide(1)">Binary Classification Problem</li>
                <li onclick="showSlide(2)">Logistic Function (Sigmoid)</li>
                <li onclick="showSlide(3)">Decision Boundary</li>
                <li onclick="showSlide(4)">Cost Function and Gradient Descent</li>
                <li onclick="showSlide(5)">Multiclass Logistic Regression</li>
                <li onclick="showSlide(6)">Regularization</li>
                <li onclick="showSlide(7)">Implementation Example</li>
                <li onclick="showSlide(8)">Evaluation Metrics</li>
                <li onclick="showSlide(9)">Applications</li>
                <li onclick="showSlide(10)">Summary</li>
            </ul>
        </div>

        <!-- Slide 1: Introduction -->
        <div class="slide active">
            <h1>Logistic Regression in Machine Learning</h1>
            <div class="svg-container">
                <svg width="500" height="300" viewBox="0 0 500 300">
                    <defs>
                        <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
                            <stop offset="0%" style="stop-color:#3498db;stop-opacity:1" />
                            <stop offset="100%" style="stop-color:#e74c3c;stop-opacity:1" />
                        </linearGradient>
                    </defs>
                    <rect x="50" y="50" width="400" height="200" rx="10" ry="10" fill="url(#grad1)" opacity="0.2"/>
                    <path d="M100,150 Q200,50 300,150 T400,150" stroke="#3498db" stroke-width="3" fill="none"/>
                    <circle cx="100" cy="150" r="5" fill="#3498db"/>
                    <circle cx="200" cy="100" r="5" fill="#3498db"/>
                    <circle cx="300" cy="150" r="5" fill="#3498db"/>
                    <circle cx="400" cy="150" r="5" fill="#3498db"/>
                    <text x="250" y="200" text-anchor="middle" font-size="18" font-weight="bold">Logistic Regression</text>
                    <text x="250" y="230" text-anchor="middle" font-size="14">Classification Algorithm</text>
                </svg>
            </div>
            <div class="grid-container">
                <div>
                    <h3>What is Logistic Regression?</h3>
                    <ul>
                        <li>A supervised learning algorithm used for <span class="highlight">classification tasks</span></li>
                        <li>Despite its name, it's used for classification, not regression</li>
                        <li>Models the probability of an input belonging to a certain class</li>
                        <li>Uses the logistic (sigmoid) function to output values between 0 and 1</li>
                    </ul>
                </div>
                <div>
                    <h3>Key Characteristics</h3>
                    <ul>
                        <li>Simple, interpretable, and efficient</li>
                        <li>Provides probability estimates</li>
                        <li>Can be extended to multiclass problems</li>
                        <li>Serves as a baseline for more complex algorithms</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 2: Binary Classification Problem -->
        <div class="slide">
            <h2>Binary Classification Problem</h2>
            <p>In binary classification, we need to classify input data into one of two classes (e.g., yes/no, true/false, 1/0).</p>
            
            <div class="example-box">
                <div class="example-title">Example: Email Spam Detection</div>
                <p>Given an email, we want to classify it as either "spam" or "not spam".</p>
                <ul>
                    <li>Input: Features extracted from email (word frequencies, sender, etc.)</li>
                    <li>Output: Probability that the email is spam</li>
                    <li>Decision: If probability > 0.5, classify as spam</li>
                </ul>
            </div>
            
            <div class="svg-container">
                <svg width="600" height="300" viewBox="0 0 600 300">
                    <!-- Axes -->
                    <line x1="50" y1="250" x2="550" y2="250" stroke="#333" stroke-width="2"/>
                    <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                    
                    <!-- Labels -->
                    <text x="300" y="280" text-anchor="middle" font-size="14">Feature X</text>
                    <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">Feature Y</text>
                    
                    <!-- Class 0 points -->
                    <circle cx="100" cy="200" r="5" fill="#3498db"/>
                    <circle cx="150" cy="180" r="5" fill="#3498db"/>
                    <circle cx="120" cy="220" r="5" fill="#3498db"/>
                    <circle cx="180" cy="190" r="5" fill="#3498db"/>
                    <circle cx="140" cy="210" r="5" fill="#3498db"/>
                    
                    <!-- Class 1 points -->
                    <circle cx="400" cy="100" r="5" fill="#e74c3c"/>
                    <circle cx="450" cy="120" r="5" fill="#e74c3c"/>
                    <circle cx="420" cy="80" r="5" fill="#e74c3c"/>
                    <circle cx="480" cy="110" r="5" fill="#e74c3c"/>
                    <circle cx="440" cy="90" r="5" fill="#e74c3c"/>
                    
                    <!-- Decision boundary -->
                    <line x1="250" y1="50" x2="250" y2="250" stroke="#2ecc71" stroke-width="2" stroke-dasharray="5,5"/>
                    
                    <!-- Legend -->
                    <circle cx="500" cy="200" r="5" fill="#3498db"/>
                    <text x="510" y="205" font-size="12">Class 0 (Not Spam)</text>
                    
                    <circle cx="500" cy="220" r="5" fill="#e74c3c"/>
                    <text x="510" y="225" font-size="12">Class 1 (Spam)</text>
                    
                    <line x1="500" y1="240" x2="520" y2="240" stroke="#2ecc71" stroke-width="2" stroke-dasharray="5,5"/>
                    <text x="525" y="245" font-size="12">Decision Boundary</text>
                </svg>
            </div>
            
            <p>The goal is to find a decision boundary that best separates the two classes. Logistic regression models the probability that a given input point belongs to a particular class.</p>
        </div>

        <!-- Slide 3: Logistic Function (Sigmoid) -->
        <div class="slide">
            <h2>Logistic Function (Sigmoid)</h2>
            <p>The logistic function, also known as the sigmoid function, is the core of logistic regression. It maps any real-valued number to a value between 0 and 1.</p>
            
            <div class="formula">
                σ(z) = 1 / (1 + e<sup>-z</sup>)
            </div>
            
            <p>Where z = w<sup>T</sup>x + b (linear combination of weights and features)</p>
            
            <div class="svg-container">
                <svg width="600" height="350" viewBox="0 0 600 350">
                    <!-- Axes -->
                    <line x1="50" y1="300" x2="550" y2="300" stroke="#333" stroke-width="2"/>
                    <line x1="50" y1="300" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                    
                    <!-- X-axis labels -->
                    <text x="50" y="320" text-anchor="middle" font-size="12">-5</text>
                    <text x="175" y="320" text-anchor="middle" font-size="12">-2.5</text>
                    <text x="300" y="320" text-anchor="middle" font-size="12">0</text>
                    <text x="425" y="320" text-anchor="middle" font-size="12">2.5</text>
                    <text x="550" y="320" text-anchor="middle" font-size="12">5</text>
                    
                    <!-- Y-axis labels -->
                    <text x="30" y="305" text-anchor="end" font-size="12">0</text>
                    <text x="30" y="180" text-anchor="end" font-size="12">0.5</text>
                    <text x="30" y="55" text-anchor="end" font-size="12">1</text>
                    
                    <!-- Axis titles -->
                    <text x="300" y="340" text-anchor="middle" font-size="14">z = w<sup>T</sup>x + b</text>
                    <text x="20" y="175" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 175)">σ(z)</text>
                    
                    <!-- Sigmoid curve -->
                    <path d="M50,295 Q100,290 150,270 T200,220 T250,150 T300,100 T350,70 T400,55 T450,52 T500,51 T550,50" 
                          stroke="#3498db" stroke-width="3" fill="none"/>
                    
                    <!-- Horizontal line at y=0.5 -->
                    <line x1="50" y1="175" x2="550" y2="175" stroke="#95a5a6" stroke-width="1" stroke-dasharray="5,5"/>
                    
                    <!-- Vertical line at z=0 -->
                    <line x1="300" y1="50" x2="300" y2="300" stroke="#95a5a6" stroke-width="1" stroke-dasharray="5,5"/>
                    
                    <!-- Point at (0, 0.5) -->
                    <circle cx="300" cy="175" r="5" fill="#e74c3c"/>
                    
                    <!-- Annotations -->
                    <text x="310" y="165" font-size="12">(0, 0.5)</text>
                    <text x="320" y="90" font-size="12">σ(z) → 1 as z → ∞</text>
                    <text x="100" y="260" font-size="12">σ(z) → 0 as z → -∞</text>
                </svg>
            </div>
            
            <div class="grid-container">
                <div>
                    <h3>Properties of Sigmoid Function</h3>
                    <ul>
                        <li>Output range: (0, 1)</li>
                        <li>S-shaped curve</li>
                        <li>Differentiable everywhere</li>
                        <li>Symmetric around point (0, 0.5)</li>
                    </ul>
                </div>
                <div>
                    <h3>Why Use Sigmoid?</h3>
                    <ul>
                        <li>Converts linear output to probability</li>
                        <li>Smooth gradient helps optimization</li>
                        <li>Clear probabilistic interpretation</li>
                        <li>Derivative is simple: σ'(z) = σ(z)(1-σ(z))</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 4: Decision Boundary -->
        <div class="slide">
            <h2>Decision Boundary</h2>
            <p>The decision boundary is the surface that separates the different classes in the feature space. For logistic regression, it's defined by the set of points where the probability equals 0.5.</p>
            
            <div class="formula">
                P(y=1|x) = 0.5 when w<sup>T</sup>x + b = 0
            </div>
            
            <div class="tab-container">
                <div class="tabs">
                    <div class="tab active" onclick="openTab(event, 'linear-boundary')">Linear Boundary</div>
                    <div class="tab" onclick="openTab(event, 'nonlinear-boundary')">Nonlinear Boundary</div>
                </div>
                
                <div id="linear-boundary" class="tab-content active">
                    <div class="svg-container">
                        <svg width="500" height="400" viewBox="0 0 500 400">
                            <!-- Axes -->
                            <line x1="50" y1="350" x2="450" y2="350" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="350" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="380" text-anchor="middle" font-size="14">Feature 1</text>
                            <text x="20" y="200" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 200)">Feature 2</text>
                            
                            <!-- Class 0 points -->
                            <circle cx="100" cy="300" r="5" fill="#3498db"/>
                            <circle cx="150" cy="280" r="5" fill="#3498db"/>
                            <circle cx="120" cy="320" r="5" fill="#3498db"/>
                            <circle cx="180" cy="290" r="5" fill="#3498db"/>
                            <circle cx="140" cy="310" r="5" fill="#3498db"/>
                            <circle cx="200" cy="270" r="5" fill="#3498db"/>
                            <circle cx="170" cy="330" r="5" fill="#3498db"/>
                            
                            <!-- Class 1 points -->
                            <circle cx="300" cy="150" r="5" fill="#e74c3c"/>
                            <circle cx="350" cy="170" r="5" fill="#e74c3c"/>
                            <circle cx="320" cy="130" r="5" fill="#e74c3c"/>
                            <circle cx="380" cy="160" r="5" fill="#e74c3c"/>
                            <circle cx="340" cy="140" r="5" fill="#e74c3c"/>
                            <circle cx="400" cy="120" r="5" fill="#e74c3c"/>
                            <circle cx="360" cy="180" r="5" fill="#e74c3c"/>
                            
                            <!-- Linear decision boundary -->
                            <line x1="220" y1="100" x2="220" y2="350" stroke="#2ecc71" stroke-width="3"/>
                            
                            <!-- Legend -->
                            <circle cx="400" cy="300" r="5" fill="#3498db"/>
                            <text x="410" y="305" font-size="12">Class 0</text>
                            
                            <circle cx="400" cy="320" r="5" fill="#e74c3c"/>
                            <text x="410" y="325" font-size="12">Class 1</text>
                            
                            <line x1="400" y1="340" x2="420" y2="340" stroke="#2ecc71" stroke-width="3"/>
                            <text x="425" y="345" font-size="12">Decision Boundary</text>
                        </svg>
                    </div>
                    <p>For a linear decision boundary, the equation is of the form w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + b = 0, which represents a straight line in 2D space.</p>
                </div>
                
                <div id="nonlinear-boundary" class="tab-content">
                    <div class="svg-container">
                        <svg width="500" height="400" viewBox="0 0 500 400">
                            <!-- Axes -->
                            <line x1="50" y1="350" x2="450" y2="350" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="350" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="380" text-anchor="middle" font-size="14">Feature 1</text>
                            <text x="20" y="200" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 200)">Feature 2</text>
                            
                            <!-- Class 0 points (inside circle) -->
                            <circle cx="250" cy="200" r="5" fill="#3498db"/>
                            <circle cx="230" cy="180" r="5" fill="#3498db"/>
                            <circle cx="270" cy="220" r="5" fill="#3498db"/>
                            <circle cx="220" cy="210" r="5" fill="#3498db"/>
                            <circle cx="280" cy="190" r="5" fill="#3498db"/>
                            <circle cx="240" cy="230" r="5" fill="#3498db"/>
                            <circle cx="260" cy="170" r="5" fill="#3498db"/>
                            
                            <!-- Class 1 points (outside circle) -->
                            <circle cx="150" cy="150" r="5" fill="#e74c3c"/>
                            <circle cx="350" cy="250" r="5" fill="#e74c3c"/>
                            <circle cx="150" cy="250" r="5" fill="#e74c3c"/>
                            <circle cx="350" cy="150" r="5" fill="#e74c3c"/>
                            <circle cx="180" cy="120" r="5" fill="#e74c3c"/>
                            <circle cx="320" cy="280" r="5" fill="#e74c3c"/>
                            <circle cx="120" cy="200" r="5" fill="#e74c3c"/>
                            <circle cx="380" cy="200" r="5" fill="#e74c3c"/>
                            
                            <!-- Nonlinear decision boundary (circle) -->
                            <circle cx="250" cy="200" r="80" stroke="#2ecc71" stroke-width="3" fill="none"/>
                            
                            <!-- Legend -->
                            <circle cx="400" cy="300" r="5" fill="#3498db"/>
                            <text x="410" y="305" font-size="12">Class 0</text>
                            
                            <circle cx="400" cy="320" r="5" fill="#e74c3c"/>
                            <text x="410" y="325" font-size="12">Class 1</text>
                            
                            <circle cx="410" cy="340" r="10" stroke="#2ecc71" stroke-width="3" fill="none"/>
                            <text x="425" y="345" font-size="12">Decision Boundary</text>
                        </svg>
                    </div>
                    <p>For nonlinear decision boundaries, we can use feature engineering (e.g., adding polynomial features) or kernel methods. The equation becomes more complex, such as w<sub>1</sub>x<sub>1</sub><sup>2</sup> + w<sub>2</sub>x<sub>2</sub><sup>2</sup> + b = 0, which represents a circle in 2D space.</p>
                </div>
            </div>
            
            <div class="example-box">
                <div class="example-title">Example: Tumor Classification</div>
                <p>In medical diagnosis, logistic regression can help classify tumors as benign or malignant based on features like size, texture, and shape. The decision boundary separates the two classes in the feature space.</p>
            </div>
        </div>

        <!-- Slide 5: Cost Function and Gradient Descent -->
        <div class="slide">
            <h2>Cost Function and Gradient Descent</h2>
            <p>To train a logistic regression model, we need to define a cost function that measures how well the model is performing and then minimize this cost using optimization algorithms like gradient descent.</p>
            
            <h3>Cost Function for Logistic Regression</h3>
            <p>Unlike linear regression, the squared error cost function doesn't work well for logistic regression because it's non-convex. Instead, we use the log loss (cross-entropy) function:</p>
            
            <div class="formula">
                J(w,b) = -1/m ∑[y<sup>(i)</sup>log(ŷ<sup>(i)</sup>) + (1-y<sup>(i)</sup>)log(1-ŷ<sup>(i)</sup>)]
            </div>
            
            <p>Where:</p>
            <ul>
                <li>m = number of training examples</li>
                <li>y<sup>(i)</sup> = actual label (0 or 1)</li>
                <li>ŷ<sup>(i)</sup> = predicted probability (σ(w<sup>T</sup>x<sup>(i)</sup> + b))</li>
            </ul>
            
            <div class="svg-container">
                <svg width="600" height="300" viewBox="0 0 600 300">
                    <!-- Axes -->
                    <line x1="50" y1="250" x2="550" y2="250" stroke="#333" stroke-width="2"/>
                    <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                    
                    <!-- Labels -->
                    <text x="300" y="280" text-anchor="middle" font-size="14">Predicted Probability (ŷ)</text>
                    <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">Cost</text>
                    
                    <!-- Cost when y=1 -->
                    <path d="M50,250 Q100,240 150,200 T250,100 T350,70 T450,55 T550,50" 
                          stroke="#e74c3c" stroke-width="3" fill="none"/>
                    
                    <!-- Cost when y=0 -->
                    <path d="M50,50 Q100,60 150,100 T250,200 T350,230 T450,245 T550,250" 
                          stroke="#3498db" stroke-width="3" fill="none"/>
                    
                    <!-- Legend -->
                    <line x1="400" y1="100" x2="430" y2="100" stroke="#e74c3c" stroke-width="3"/>
                    <text x="435" y="105" font-size="12">Cost when y=1</text>
                    
                    <line x1="400" y1="120" x2="430" y2="120" stroke="#3498db" stroke-width="3"/>
                    <text x="435" y="125" font-size="12">Cost when y=0</text>
                    
                    <!-- Annotations -->
                    <text x="460" y="70" font-size="12">Cost → 0 as ŷ → 1</text>
                    <text x="460" y="230" font-size="12">Cost → 0 as ŷ → 0</text>
                    <text x="60" y="70" font-size="12">Cost → ∞ as ŷ → 0</text>
                    <text x="60" y="230" font-size="12">Cost → ∞ as ŷ → 1</text>
                </svg>
            </div>
            
            <h3>Gradient Descent</h3>
            <p>To minimize the cost function, we use gradient descent to update the parameters:</p>
            
            <div class="formula">
                w<sub>j</sub> := w<sub>j</sub> - α ∂J(w,b)/∂w<sub>j</sub>
            </div>
            
            <div class="formula">
                b := b - α ∂J(w,b)/∂b
            </div>
            
            <p>Where α is the learning rate. The gradients are:</p>
            
            <div class="formula">
                ∂J(w,b)/∂w<sub>j</sub> = 1/m ∑(ŷ<sup>(i)</sup> - y<sup>(i)</sup>)x<sub>j</sub><sup>(i)</sup>
            </div>
            
            <div class="formula">
                ∂J(w,b)/∂b = 1/m ∑(ŷ<sup>(i)</sup> - y<sup>(i)</sup>)
            </div>
            
            <div class="example-box">
                <div class="example-title">Gradient Descent Visualization</div>
                <p>Imagine a 3D surface where the x and y axes represent the parameters w and b, and the z-axis represents the cost. Gradient descent starts at a random point on this surface and takes steps in the direction of steepest descent until it reaches a minimum.</p>
            </div>
        </div>

        <!-- Slide 6: Multiclass Logistic Regression -->
        <div class="slide">
            <h2>Multiclass Logistic Regression</h2>
            <p>While basic logistic regression is designed for binary classification, it can be extended to handle multiple classes through various approaches.</p>
            
            <div class="tab-container">
                <div class="tabs">
                    <div class="tab active" onclick="openTab(event, 'one-vs-rest')">One-vs-Rest (OvR)</div>
                    <div class="tab" onclick="openTab(event, 'softmax')">Softmax Regression</div>
                </div>
                
                <div id="one-vs-rest" class="tab-content active">
                    <h3>One-vs-Rest (OvR) Approach</h3>
                    <p>In the One-vs-Rest approach, we train K separate binary classifiers, where K is the number of classes. Each classifier is trained to distinguish one class from all other classes.</p>
                    
                    <div class="svg-container">
                        <svg width="500" height="350" viewBox="0 0 500 350">
                            <!-- Axes -->
                            <line x1="50" y1="300" x2="450" y2="300" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="300" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="330" text-anchor="middle" font-size="14">Feature 1</text>
                            <text x="20" y="175" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 175)">Feature 2</text>
                            
                            <!-- Class 0 points -->
                            <circle cx="100" cy="250" r="5" fill="#3498db"/>
                            <circle cx="150" cy="230" r="5" fill="#3498db"/>
                            <circle cx="120" cy="270" r="5" fill="#3498db"/>
                            <circle cx="180" cy="240" r="5" fill="#3498db"/>
                            <circle cx="140" cy="260" r="5" fill="#3498db"/>
                            
                            <!-- Class 1 points -->
                            <circle cx="250" cy="150" r="5" fill="#e74c3c"/>
                            <circle cx="300" cy="170" r="5" fill="#e74c3c"/>
                            <circle cx="270" cy="130" r="5" fill="#e74c3c"/>
                            <circle cx="330" cy="160" r="5" fill="#e74c3c"/>
                            <circle cx="290" cy="140" r="5" fill="#e74c3c"/>
                            
                            <!-- Class 2 points -->
                            <circle cx="350" cy="250" r="5" fill="#2ecc71"/>
                            <circle cx="400" cy="230" r="5" fill="#2ecc71"/>
                            <circle cx="370" cy="270" r="5" fill="#2ecc71"/>
                            <circle cx="430" cy="240" r="5" fill="#2ecc71"/>
                            <circle cx="390" cy="260" r="5" fill="#2ecc71"/>
                            
                            <!-- Decision boundaries -->
                            <line x1="200" y1="50" x2="200" y2="300" stroke="#3498db" stroke-width="2" stroke-dasharray="5,5"/>
                            <line x1="320" y1="50" x2="320" y2="300" stroke="#e74c3c" stroke-width="2" stroke-dasharray="5,5"/>
                            
                            <!-- Legend -->
                            <circle cx="400" cy="80" r="5" fill="#3498db"/>
                            <text x="410" y="85" font-size="12">Class 0</text>
                            
                            <circle cx="400" cy="100" r="5" fill="#e74c3c"/>
                            <text x="410" y="105" font-size="12">Class 1</text>
                            
                            <circle cx="400" cy="120" r="5" fill="#2ecc71"/>
                            <text x="410" y="125" font-size="12">Class 2</text>
                            
                            <line x1="400" y1="140" x2="420" y2="140" stroke="#3498db" stroke-width="2" stroke-dasharray="5,5"/>
                            <text x="425" y="145" font-size="12">Boundary 0</text>
                            
                            <line x1="400" y1="160" x2="420" y2="160" stroke="#e74c3c" stroke-width="2" stroke-dasharray="5,5"/>
                            <text x="425" y="165" font-size="12">Boundary 1</text>
                        </svg>
                    </div>
                    
                    <p>For a new input, we run all K classifiers and choose the class with the highest probability.</p>
                </div>
                
                <div id="softmax" class="tab-content">
                    <h3>Softmax Regression</h3>
                    <p>Softmax regression (also known as multinomial logistic regression) generalizes logistic regression to multiple classes by using the softmax function.</p>
                    
                    <div class="formula">
                        P(y=k|x) = e<sup>w<sub>k</sub><sup>T</sup>x</sup> / ∑<sub>j=1</sub><sup>K</sup> e<sup>w<sub>j</sub><sup>T</sup>x</sup>
                    </div>
                    
                    <p>Where K is the number of classes, and w<sub>k</sub> is the weight vector for class k.</p>
                    
                    <div class="svg-container">
                        <svg width="500" height="300" viewBox="0 0 500 300">
                            <!-- Axes -->
                            <line x1="50" y1="250" x2="450" y2="250" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="280" text-anchor="middle" font-size="14">Input (x)</text>
                            <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">Probability</text>
                            
                            <!-- Softmax curves for 3 classes -->
                            <path d="M50,230 Q150,200 250,150 T450,50" stroke="#3498db" stroke-width="3" fill="none"/>
                            <path d="M50,150 Q150,120 250,100 T450,150" stroke="#e74c3c" stroke-width="3" fill="none"/>
                            <path d="M50,70 Q150,80 250,150 T450,250" stroke="#2ecc71" stroke-width="3" fill="none"/>
                            
                            <!-- Legend -->
                            <line x1="400" y1="80" x2="430" y2="80" stroke="#3498db" stroke-width="3"/>
                            <text x="435" y="85" font-size="12">Class 0</text>
                            
                            <line x1="400" y1="100" x2="430" y2="100" stroke="#e74c3c" stroke-width="3"/>
                            <text x="435" y="105" font-size="12">Class 1</text>
                            
                            <line x1="400" y1="120" x2="430" y2="120" stroke="#2ecc71" stroke-width="3"/>
                            <text x="435" y="125" font-size="12">Class 2</text>
                            
                            <!-- Annotation -->
                            <text x="250" y="40" text-anchor="middle" font-size="12">Sum of probabilities = 1</text>
                        </svg>
                    </div>
                    
                    <p>The softmax function ensures that the predicted probabilities for all classes sum to 1, making it suitable for multiclass classification.</p>
                </div>
            </div>
            
            <div class="example-box">
                <div class="example-title">Example: Image Classification</div>
                <p>In image classification, we might want to classify images into categories like "cat", "dog", or "bird". Multiclass logistic regression can assign probabilities to each category, and we select the one with the highest probability.</p>
            </div>
        </div>

        <!-- Slide 7: Regularization -->
        <div class="slide">
            <h2>Regularization</h2>
            <p>Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function. It discourages complex models by penalizing large parameter values.</p>
            
            <div class="tab-container">
                <div class="tabs">
                    <div class="tab active" onclick="openTab(event, 'l1-regularization')">L1 Regularization (Lasso)</div>
                    <div class="tab" onclick="openTab(event, 'l2-regularization')">L2 Regularization (Ridge)</div>
                    <div class="tab" onclick="openTab(event, 'elastic-net')">Elastic Net</div>
                </div>
                
                <div id="l1-regularization" class="tab-content active">
                    <h3>L1 Regularization (Lasso)</h3>
                    <p>L1 regularization adds the absolute value of the magnitude of coefficients as a penalty term to the cost function:</p>
                    
                    <div class="formula">
                        J(w,b) = -1/m ∑[y<sup>(i)</sup>log(ŷ<sup>(i)</sup>) + (1-y<sup>(i)</sup>)log(1-ŷ<sup>(i)</sup>)] + λ∑|w<sub>j</sub>|
                    </div>
                    
                    <div class="svg-container">
                        <svg width="500" height="300" viewBox="0 0 500 300">
                            <!-- Axes -->
                            <line x1="50" y1="250" x2="450" y2="250" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="280" text-anchor="middle" font-size="14">w<sub>1</sub></text>
                            <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">w<sub>2</sub></text>
                            
                            <!-- L1 constraint region (diamond) -->
                            <path d="M250,100 L350,150 L250,200 L150,150 Z" stroke="#3498db" stroke-width="3" fill="none"/>
                            
                            <!-- Contour lines of cost function -->
                            <ellipse cx="300" cy="120" rx="80" ry="40" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="60" ry="30" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="40" ry="20" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            
                            <!-- Optimal point -->
                            <circle cx="250" cy="100" r="5" fill="#2ecc71"/>
                            
                            <!-- Legend -->
                            <path d="M400,100 L410,110 L400,120 L390,110 Z" stroke="#3498db" stroke-width="2" fill="none"/>
                            <text x="415" y="115" font-size="12">L1 Constraint</text>
                            
                            <ellipse cx="405" cy="140" rx="15" ry="8" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 405, 140)"/>
                            <text x="425" y="145" font-size="12">Cost Contours</text>
                            
                            <circle cx="400" cy="170" r="5" fill="#2ecc71"/>
                            <text x="410" y="175" font-size="12">Optimal Point</text>
                        </svg>
                    </div>
                    
                    <h3>Properties of L1 Regularization:</h3>
                    <ul>
                        <li>Can produce sparse models (some weights become exactly zero)</li>
                        <li>Useful for feature selection</li>
                        <li>Robust to outliers</li>
                    </ul>
                </div>
                
                <div id="l2-regularization" class="tab-content">
                    <h3>L2 Regularization (Ridge)</h3>
                    <p>L2 regularization adds the squared magnitude of coefficients as a penalty term to the cost function:</p>
                    
                    <div class="formula">
                        J(w,b) = -1/m ∑[y<sup>(i)</sup>log(ŷ<sup>(i)</sup>) + (1-y<sup>(i)</sup>)log(1-ŷ<sup>(i)</sup>)] + λ∑w<sub>j</sub><sup>2</sup>
                    </div>
                    
                    <div class="svg-container">
                        <svg width="500" height="300" viewBox="0 0 500 300">
                            <!-- Axes -->
                            <line x1="50" y1="250" x2="450" y2="250" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="280" text-anchor="middle" font-size="14">w<sub>1</sub></text>
                            <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">w<sub>2</sub></text>
                            
                            <!-- L2 constraint region (circle) -->
                            <circle cx="250" cy="150" r="70" stroke="#3498db" stroke-width="3" fill="none"/>
                            
                            <!-- Contour lines of cost function -->
                            <ellipse cx="300" cy="120" rx="80" ry="40" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="60" ry="30" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="40" ry="20" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            
                            <!-- Optimal point -->
                            <circle cx="270" cy="110" r="5" fill="#2ecc71"/>
                            
                            <!-- Legend -->
                            <circle cx="400" cy="110" r="15" stroke="#3498db" stroke-width="2" fill="none"/>
                            <text x="420" y="115" font-size="12">L2 Constraint</text>
                            
                            <ellipse cx="405" cy="140" rx="15" ry="8" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 405, 140)"/>
                            <text x="425" y="145" font-size="12">Cost Contours</text>
                            
                            <circle cx="400" cy="170" r="5" fill="#2ecc71"/>
                            <text x="410" y="175" font-size="12">Optimal Point</text>
                        </svg>
                    </div>
                    
                    <h3>Properties of L2 Regularization:</h3>
                    <ul>
                        <li>Does not produce sparse models (weights approach but don't reach zero)</li>
                        <li>Computationally efficient due to closed-form solution</li>
                        <li>Handles multicollinearity well</li>
                    </ul>
                </div>
                
                <div id="elastic-net" class="tab-content">
                    <h3>Elastic Net</h3>
                    <p>Elastic Net combines both L1 and L2 regularization:</p>
                    
                    <div class="formula">
                        J(w,b) = -1/m ∑[y<sup>(i)</sup>log(ŷ<sup>(i)</sup>) + (1-y<sup>(i)</sup>)log(1-ŷ<sup>(i)</sup>)] + λ<sub>1</sub>∑|w<sub>j</sub>| + λ<sub>2</sub>∑w<sub>j</sub><sup>2</sup>
                    </div>
                    
                    <div class="svg-container">
                        <svg width="500" height="300" viewBox="0 0 500 300">
                            <!-- Axes -->
                            <line x1="50" y1="250" x2="450" y2="250" stroke="#333" stroke-width="2"/>
                            <line x1="50" y1="250" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                            
                            <!-- Labels -->
                            <text x="250" y="280" text-anchor="middle" font-size="14">w<sub>1</sub></text>
                            <text x="20" y="150" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 150)">w<sub>2</sub></text>
                            
                            <!-- Elastic Net constraint region (between diamond and circle) -->
                            <path d="M250,90 Q320,120 350,150 Q320,180 250,210 Q180,180 150,150 Q180,120 250,90" 
                                  stroke="#3498db" stroke-width="3" fill="none"/>
                            
                            <!-- Contour lines of cost function -->
                            <ellipse cx="300" cy="120" rx="80" ry="40" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="60" ry="30" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            <ellipse cx="300" cy="120" rx="40" ry="20" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 300, 120)"/>
                            
                            <!-- Optimal point -->
                            <circle cx="260" cy="105" r="5" fill="#2ecc71"/>
                            
                            <!-- Legend -->
                            <path d="M400,90 Q420,105 430,120 Q420,135 400,150 Q380,135 370,120 Q380,105 400,90" 
                                  stroke="#3498db" stroke-width="2" fill="none"/>
                            <text x="435" y="125" font-size="12">Elastic Net</text>
                            
                            <ellipse cx="405" cy="160" rx="15" ry="8" stroke="#e74c3c" stroke-width="2" fill="none" transform="rotate(30, 405, 160)"/>
                            <text x="425" y="165" font-size="12">Cost Contours</text>
                            
                            <circle cx="400" cy="190" r="5" fill="#2ecc71"/>
                            <text x="410" y="195" font-size="12">Optimal Point</text>
                        </svg>
                    </div>
                    
                    <h3>Properties of Elastic Net:</h3>
                    <ul>
                        <li>Combines benefits of both L1 and L2 regularization</li>
                        <li>Can select variables like L1 while maintaining the regularization properties of L2</li>
                        <li>Particularly useful when there are multiple correlated features</li>
                    </ul>
                </div>
            </div>
            
            <div class="example-box">
                <div class="example-title">Choosing the Right Regularization</div>
                <p>The choice of regularization depends on the problem:</p>
                <ul>
                    <li><strong>L1</strong>: When you have many features and believe only a few are important</li>
                    <li><strong>L2</strong>: When you have many correlated features or want to keep all features with small weights</li>
                    <li><strong>Elastic Net</strong>: When you want a balance between L1 and L2, especially with correlated features</li>
                </ul>
            </div>
        </div>

        <!-- Slide 8: Implementation Example -->
        <div class="slide">
            <h2>Implementation Example</h2>
            <p>Let's implement logistic regression from scratch in Python to classify iris flowers based on their sepal and petal measurements.</p>
            
            <div class="code-block">
                <pre># Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target

# For simplicity, let's use only two classes (setosa and versicolor)
X = X[:100]
y = y[:100]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Add intercept term
X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))
X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))</pre>
            </div>
            
            <div class="code-block">
                <pre># Define the sigmoid function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Define the cost function
def compute_cost(X, y, theta):
    m = len(y)
    h = sigmoid(X.dot(theta))
    cost = (-1/m) * np.sum(y * np.log(h) + (1-y) * np.log(1-h))
    return cost

# Define gradient descent
def gradient_descent(X, y, theta, alpha, num_iters):
    m = len(y)
    cost_history = []
    
    for i in range(num_iters):
        h = sigmoid(X.dot(theta))
        gradient = (1/m) * X.T.dot(h - y)
        theta -= alpha * gradient
        cost = compute_cost(X, y, theta)
        cost_history.append(cost)
        
        if i % 100 == 0:
            print(f"Iteration {i}, Cost: {cost}")
    
    return theta, cost_history</pre>
            </div>
            
            <div class="code-block">
                <pre># Initialize parameters
theta = np.zeros(X_train.shape[1])
alpha = 0.1
num_iters = 1000

# Run gradient descent
theta, cost_history = gradient_descent(X_train, y_train, theta, alpha, num_iters)

# Plot cost over iterations
plt.plot(range(num_iters), cost_history)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost Function Convergence')
plt.show()

# Make predictions on the test set
def predict(X, theta):
    return sigmoid(X.dot(theta)) >= 0.5

y_pred = predict(X_test, theta)

# Calculate accuracy
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy: {accuracy * 100:.2f}%")</pre>
            </div>
            
            <div class="example-box">
                <div class="example-title">Using scikit-learn</div>
                <p>For practical applications, you can use the scikit-learn library, which provides an optimized implementation of logistic regression:</p>
                
                <div class="code-block">
                    <pre>from sklearn.linear_model import LogisticRegression

# Create and fit the model
model = LogisticRegression()
model.fit(X_train[:, 1:], y_train)  # Exclude the intercept column

# Make predictions
y_pred = model.predict(X_test[:, 1:])

# Calculate accuracy
accuracy = model.score(X_test[:, 1:], y_test)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Get the coefficients
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)</pre>
                </div>
            </div>
        </div>

        <!-- Slide 9: Evaluation Metrics -->
        <div class="slide">
            <h2>Evaluation Metrics</h2>
            <p>To assess the performance of a logistic regression model, we use various evaluation metrics. Let's explore the most common ones.</p>
            
            <h3>Confusion Matrix</h3>
            <p>A confusion matrix is a table that summarizes the performance of a classification algorithm:</p>
            
            <div class="svg-container">
                <svg width="400" height="300" viewBox="0 0 400 300">
                    <!-- Table structure -->
                    <rect x="50" y="50" width="300" height="200" stroke="#333" stroke-width="2" fill="none"/>
                    
                    <!-- Vertical lines -->
                    <line x1="200" y1="50" x2="200" y2="250" stroke="#333" stroke-width="2"/>
                    
                    <!-- Horizontal lines -->
                    <line x1="50" y1="150" x2="350" y2="150" stroke="#333" stroke-width="2"/>
                    
                    <!-- Labels -->
                    <text x="125" y="35" text-anchor="middle" font-size="14" font-weight="bold">Predicted</text>
                    <text x="15" y="150" text-anchor="middle" font-size="14" font-weight="bold" transform="rotate(-90, 15, 150)">Actual</text>
                    
                    <text x="125" y="80" text-anchor="middle" font-size="14">Positive</text>
                    <text x="275" y="80" text-anchor="middle" font-size="14">Negative</text>
                    
                    <text x="125" y="180" text-anchor="middle" font-size="14">Positive</text>
                    <text x="275" y="180" text-anchor="middle" font-size="14">Negative</text>
                    
                    <!-- Cell contents -->
                    <text x="125" y="115" text-anchor="middle" font-size="16" font-weight="bold">TP</text>
                    <text x="275" y="115" text-anchor="middle" font-size="16" font-weight="bold">FN</text>
                    <text x="125" y="215" text-anchor="middle" font-size="16" font-weight="bold">FP</text>
                    <text x="275" y="215" text-anchor="middle" font-size="16" font-weight="bold">TN</text>
                    
                    <!-- Explanations -->
                    <text x="125" y="135" text-anchor="middle" font-size="12">(True Positive)</text>
                    <text x="275" y="135" text-anchor="middle" font-size="12">(False Negative)</text>
                    <text x="125" y="235" text-anchor="middle" font-size="12">(False Positive)</text>
                    <text x="275" y="235" text-anchor="middle" font-size="12">(True Negative)</text>
                </svg>
            </div>
            
            <div class="grid-container">
                <div>
                    <h3>Common Metrics</h3>
                    <ul>
                        <li><strong>Accuracy</strong>: (TP + TN) / (TP + TN + FP + FN)</li>
                        <li><strong>Precision</strong>: TP / (TP + FP)</li>
                        <li><strong>Recall (Sensitivity)</strong>: TP / (TP + FN)</li>
                        <li><strong>F1 Score</strong>: 2 × (Precision × Recall) / (Precision + Recall)</li>
                        <li><strong>Specificity</strong>: TN / (TN + FP)</li>
                    </ul>
                </div>
                <div>
                    <h3>ROC Curve and AUC</h3>
                    <p>The Receiver Operating Characteristic (ROC) curve plots the true positive rate (recall) against the false positive rate (1 - specificity) at various threshold settings.</p>
                    <p>The Area Under the Curve (AUC) represents the degree or measure of separability. Higher AUC indicates better model performance.</p>
                </div>
            </div>
            
            <div class="svg-container">
                <svg width="500" height="350" viewBox="0 0 500 350">
                    <!-- Axes -->
                    <line x1="50" y1="300" x2="450" y2="300" stroke="#333" stroke-width="2"/>
                    <line x1="50" y1="300" x2="50" y2="50" stroke="#333" stroke-width="2"/>
                    
                    <!-- Labels -->
                    <text x="250" y="330" text-anchor="middle" font-size="14">False Positive Rate</text>
                    <text x="20" y="175" text-anchor="middle" font-size="14" transform="rotate(-90, 20, 175)">True Positive Rate</text>
                    
                    <!-- Diagonal line (random classifier) -->
                    <line x1="50" y1="300" x2="450" y2="50" stroke="#95a5a6" stroke-width="2" stroke-dasharray="5,5"/>
                    
                    <!-- ROC curve -->
                    <path d="M50,300 Q100,280 150,200 T250,100 T350,70 T450,50" 
                          stroke="#3498db" stroke-width="3" fill="none"/>
                    
                    <!-- AUC area -->
                    <path d="M50,300 L50,300 Q100,280 150,200 T250,100 T350,70 T450,50 L450,300 Z" 
                          fill="#3498db" opacity="0.2"/>
                    
                    <!-- Legend -->
                    <line x1="350" y1="250" x2="380" y2="250" stroke="#3498db" stroke-width="3"/>
                    <text x="385" y="255" font-size="12">ROC Curve</text>
                    
                    <line x1="350" y1="270" x2="380" y2="270" stroke="#95a5a6" stroke-width="2" stroke-dasharray="5,5"/>
                    <text x="385" y="275" font-size="12">Random Classifier</text>
                    
                    <!-- AUC annotation -->
                    <text x="250" y="200" text-anchor="middle" font-size="14" font-weight="bold">AUC = 0.85</text>
                </svg>
            </div>
            
            <div class="example-box">
                <div class="example-title">Choosing the Right Metric</div>
                <p>The choice of evaluation metric depends on the problem:</p>
                <ul>
                    <li><strong>Accuracy</strong>: When classes are balanced</li>
                    <li><strong>Precision</strong>: When false positives are costly (e.g., spam detection)</li>
                    <li><strong>Recall</strong>: When false negatives are costly (e.g., disease diagnosis)</li>
                    <li><strong>F1 Score</strong>: When you need a balance between precision and recall</li>
                </ul>
            </div>
        </div>

        <!-- Slide 10: Applications -->
        <div class="slide">
            <h2>Applications of Logistic Regression</h2>
            <p>Logistic regression is widely used across various domains due to its simplicity, interpretability, and efficiency. Let's explore some common applications.</p>
            
            <div class="grid-container">
                <div>
                    <h3>Healthcare</h3>
                    <ul>
                        <li>Disease diagnosis and prediction</li>
                        <li>Patient risk assessment</li>
                        <li>Treatment effectiveness analysis</li>
                        <li>Medical image classification</li>
                    </ul>
                    
                    <div class="example-box">
                        <div class="example-title">Example: Heart Disease Prediction</div>
                        <p>Logistic regression can predict the likelihood of a patient developing heart disease based on factors like age, cholesterol levels, blood pressure, and lifestyle habits.</p>
                    </div>
                </div>
                <div>
                    <h3>Finance</h3>
                    <ul>
                        <li>Credit scoring</li>
                        <li>Fraud detection</li>
                        <li>Loan default prediction</li>
                        <li>Customer churn analysis</li>
                    </ul>
                    
                    <div class="example-box">
                        <div class="example-title">Example: Credit Scoring</div>
                        <p>Banks use logistic regression to assess the creditworthiness of loan applicants by analyzing their credit history, income, and other financial indicators.</p>
                    </div>
                </div>
            </div>
            
            <div class="grid-container">
                <div>
                    <h3>Marketing</h3>
                    <ul>
                        <li>Customer segmentation</li>
                        <li>Response prediction</li>
                        <li>Churn prediction</li>
                        <li>Targeted advertising</li>
                    </ul>
                    
                    <div class="example-box">
                        <div class="example-title">Example: Customer Churn Prediction</div>
                        <p>Companies use logistic regression to predict which customers are likely to stop using their services, allowing them to take proactive retention measures.</p>
                    </div>
                </div>
                <div>
                    <h3>Technology</h3>
                    <ul>
                        <li>Spam detection</li>
                        <li>Sentiment analysis</li>
                        <li>Image classification</li>
                        <li>Recommendation systems</li>
                    </ul>
                    
                    <div class="example-box">
                        <div class="example-title">Example: Spam Detection</div>
                        <p>Email services use logistic regression to classify emails as spam or not spam based on features like sender information, content, and metadata.</p>
                    </div>
                </div>
            </div>
            
            <h3>Advantages in Real-World Applications</h3>
            <ul>
                <li><strong>Interpretability</strong>: Coefficients provide insights into feature importance</li>
                <li><strong>Efficiency</strong>: Fast training and prediction, suitable for real-time applications</li>
                <li><strong>Probability outputs</strong>: Provides confidence scores for predictions</li>
                <li><strong>Low resource requirements</strong>: Doesn't require extensive computational resources</li>
                <li><strong>Baseline model</strong>: Serves as a good starting point for more complex models</li>
            </ul>
        </div>

        <!-- Slide 11: Summary -->
        <div class="slide">
            <h2>Summary</h2>
            <p>Let's recap what we've learned about logistic regression in machine learning.</p>
            
            <div class="svg-container">
                <svg width="600" height="250" viewBox="0 0 600 250">
                    <!-- Central concept -->
                    <circle cx="300" cy="125" r="60" fill="#3498db" opacity="0.7"/>
                    <text x="300" y="130" text-anchor="middle" font-size="16" font-weight="bold" fill="white">Logistic Regression</text>
                    
                    <!-- Key concepts -->
                    <circle cx="150" cy="80" r="40" fill="#e74c3c" opacity="0.7"/>
                    <text x="150" y="85" text-anchor="middle" font-size="12" fill="white">Classification</text>
                    
                    <circle cx="450" cy="80" r="40" fill="#e74c3c" opacity="0.7"/>
                    <text x="450" y="85" text-anchor="middle" font-size="12" fill="white">Sigmoid</text>
                    
                    <circle cx="150" cy="170" r="40" fill="#e74c3c" opacity="0.7"/>
                    <text x="150" y="175" text-anchor="middle" font-size="12" fill="white">Cost Function</text>
                    
                    <circle cx="450" cy="170" r="40" fill="#e74c3c" opacity="0.7"/>
                    <text x="450" y="175" text-anchor="middle" font-size="12" fill="white">Optimization</text>
                    
                    <!-- Connections -->
                    <line x1="190" y1="95" x2="250" y2="110" stroke="#333" stroke-width="2"/>
                    <line x1="410" y1="95" x2="350" y2="110" stroke="#333" stroke-width="2"/>
                    <line x1="190" y1="155" x2="250" y2="140" stroke="#333" stroke-width="2"/>
                    <line x1="410" y1="155" x2="350" y2="140" stroke="#333" stroke-width="2"/>
                </svg>
            </div>
            
            <h3>Key Takeaways</h3>
            <ul>
                <li>Logistic regression is a <span class="highlight">classification algorithm</span> despite its name</li>
                <li>It uses the <span class="highlight">sigmoid function</span> to map outputs to probabilities between 0 and 1</li>
                <li>The <span class="highlight">decision boundary</span> separates different classes in the feature space</li>
                <li>It's optimized using <span class="highlight">gradient descent</span> with the log loss cost function</li>
                <li>Can be extended to <span class="highlight">multiclass problems</span> using One-vs-Rest or Softmax</li>
                <li><span class="highlight">Regularization</span> helps prevent overfitting</li>
                <li>Various <span class="highlight">evaluation metrics</span> are used to assess model performance</li>
                <li>Widely applied in <span class="highlight">healthcare, finance, marketing, and technology</span></li>
            </ul>
            
            <h3>Advantages and Limitations</h3>
            <div class="grid-container">
                <div>
                    <h4>Advantages</h4>
                    <ul>
                        <li>Simple and interpretable</li>
                        <li>Computationally efficient</li>
                        <li>Provides probability estimates</li>
                        <li>Less prone to overfitting in low-dimensional datasets</li>
                        <li>Good baseline model</li>
                    </ul>
                </div>
                <div>
                    <h4>Limitations</h4>
                    <ul>
                        <li>Assumes linear decision boundary</li>
                        <li>May not perform well with complex relationships</li>
                        <li>Sensitive to outliers</li>
                        <li>Requires feature engineering for nonlinear problems</li>
                        <li>May underfit with high-dimensional data</li>
                    </ul>
                </div>
            </div>
            
            <div class="example-box">
                <div class="example-title">Next Steps</div>
                <p>After mastering logistic regression, you can explore more advanced classification algorithms like:</p>
                <ul>
                    <li>Support Vector Machines (SVM)</li>
                    <li>Decision Trees and Random Forests</li>
                    <li>Gradient Boosting Machines (XGBoost, LightGBM)</li>
                    <li>Neural Networks</li>
                </ul>
            </div>
        </div>

        <div class="navigation">
            <button id="prevBtn" onclick="changeSlide(-1)">Previous</button>
            <button id="nextBtn" onclick="changeSlide(1)">Next</button>
        </div>
        
        <div class="slide-indicator">
            <span id="slideNum">1</span> / <span id="totalSlides">11</span>
        </div>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        
        document.getElementById('totalSlides').textContent = totalSlides;
        
        function showSlide(n) {
            if (n < 0) {
                currentSlide = 0;
            } else if (n >= totalSlides) {
                currentSlide = totalSlides - 1;
            } else {
                currentSlide = n;
            }
            
            slides.forEach(slide => slide.classList.remove('active'));
            slides[currentSlide].classList.add('active');
            
            document.getElementById('slideNum').textContent = currentSlide + 1;
            
            // Update navigation buttons
            document.getElementById('prevBtn').disabled = currentSlide === 0;
            document.getElementById('nextBtn').disabled = currentSlide === totalSlides - 1;
        }
        
        function changeSlide(n) {
            showSlide(currentSlide + n);
        }
        
        function openTab(evt, tabName) {
            const tabContents = document.querySelectorAll('.tab-content');
            const tabs = document.querySelectorAll('.tab');
            
            tabContents.forEach(content => content.classList.remove('active'));
            tabs.forEach(tab => tab.classList.remove('active'));
            
            document.getElementById(tabName).classList.add('active');
            evt.currentTarget.classList.add('active');
        }
        
        // Initialize the first slide
        showSlide(0);
        
        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
            if (e.key === 'ArrowLeft') {
                changeSlide(-1);
            } else if (e.key === 'ArrowRight') {
                changeSlide(1);
            }
        });
    </script>
</body>
</html>